{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a96697",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-deployment-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abe1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AML Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "#Select AML Compute Cluster\n",
    "cpu_cluster_name = 'cpucluster'\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found an existing cluster, using it instead.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3_V2',\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=1)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    cpu_cluster.wait_for_completion(show_output=True)\n",
    "    \n",
    "#Get default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3eb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scoring_scripts/score.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from keras.layers.core import Dense \n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global scaler\n",
    "    global init_error\n",
    "    \n",
    "    try:\n",
    "\n",
    "        init_error = None\n",
    "\n",
    "        scaler_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model_files', 'scaler.pkl')\n",
    "        model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model_files', 'anomaly_detection_encoder_model.h5')\n",
    "        \n",
    "        print('Loading scaler from:', scaler_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        print(scaler)\n",
    "\n",
    "        print('Loading model from:', model_path)\n",
    "        model = load_model(model_path)\n",
    "        print(model)\n",
    "\n",
    "    except Exception as e:\n",
    "        init_error = e\n",
    "        print(e)\n",
    "        \n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "\n",
    "    if init_error is not None:\n",
    "        return 'Init error: {}'.format(str(init_error))\n",
    "\n",
    "    try:\n",
    "        print(\"Received input:\", raw_data)\n",
    "    \n",
    "        input_df = pd.read_json(raw_data, orient='values')\n",
    "        print(input_df)\n",
    "    \n",
    "        sensor_readings = np.array(input_df)\n",
    "        scaled_sensor_readings = scaler.transform(sensor_readings.reshape(1,-1))\n",
    "\n",
    "        pred_sensor_readings = model.predict(scaled_sensor_readings)\n",
    "        score = np.mean(np.abs(scaled_sensor_readings - pred_sensor_readings[0]))\n",
    "\n",
    "        if score > 0.01:\n",
    "            print('WARNING! Abnormal conditions detected')\n",
    "            return 1\n",
    "        else:\n",
    "            print('Everything is ok')\n",
    "            return 0\n",
    "\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test scoring\n",
    "    init()\n",
    "    test_row = '[[14.23, 41, 14.4, 318.50, 601.95]]'\n",
    "    prediction = run(test_row, {})\n",
    "    print(\"Test result: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3de82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "\n",
    "# Create inference configuration based on the environment definition and the entry script\n",
    "myenv = Environment.get(ws, 'tf_keras_autoencoder_env')\n",
    "inference_config = InferenceConfig(entry_script=\"scoring_scripts/score.py\", environment=myenv)\n",
    "# Create a local deployment, using port 8890 for the web service endpoint\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "model = Model(ws, name='Autoencoder_PredMaintenance')\n",
    "# Deploy the service\n",
    "service = Model.deploy(\n",
    "    ws, \"autoencoderpredmaintenance\", [model], inference_config, deployment_config)\n",
    "# Wait for the deployment to complete\n",
    "service.wait_for_deployment(True)\n",
    "# Display the port that the web service is available on\n",
    "print(service.port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e560a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#Test normal operation conditions\n",
    "test_row = json.dumps([[70, 200, 60.6, 0, 1448.17]])\n",
    "test_sample = bytes(test_row, encoding='utf8')\n",
    "prediction=service.run(input_data=test_sample)\n",
    "print('Expected Result: 0')\n",
    "print('Predicted Result: {}'.format(str(prediction)))\n",
    "\n",
    "\n",
    "#Test failure conditions\n",
    "test_row = json.dumps([[14.23, 41, 14.4, 318.50, 601.95]])\n",
    "test_sample = bytes(test_row, encoding='utf8')\n",
    "prediction=service.run(input_data=test_sample)\n",
    "print('Expected Result: 1')\n",
    "print('Predicted Result: {}'.format(str(prediction)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
