{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Develop Code for Real-Time Deployment\r\n",
    "Deployment of a model registered in an AML workspace to a real-time endpoint requires inclusion of a scoring script that loads the model of interest and formats/feeds incoming data through before returning a response. Developing this script using a `LocalWebservice` can be effective for troubleshooting any issues. [More details can be found here.](\r\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-deployment-local)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Import required packages\r\n",
    "from azureml.core import Workspace,Environment\r\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Connect to AML Workspace\r\n",
    "ws = Workspace.from_config()\r\n",
    "\r\n",
    "#Select AML Compute Cluster\r\n",
    "cpu_cluster_name = 'cpucluster'\r\n",
    "\r\n",
    "# Verify that cluster does not exist already\r\n",
    "try:\r\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\r\n",
    "    print('Found an existing cluster, using it instead.')\r\n",
    "except ComputeTargetException:\r\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3_V2',\r\n",
    "                                                           min_nodes=0,\r\n",
    "                                                           max_nodes=1)\r\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\r\n",
    "    cpu_cluster.wait_for_completion(show_output=True)\r\n",
    "    \r\n",
    "#Get default datastore\r\n",
    "default_ds = ws.get_default_datastore()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The scoring script associated with the deployed model should have a structure similar to what is shown below. All scoring files need to implement two basic methods: `init()` and `main()`. The `init()` call is responsible for loading the model artifact from the AML registry into memory. The `main()` call is responsible for formatting user-sent data, feeding it into the model, and formatting results before returning a response to the user."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile scoring_scripts/score.py\r\n",
    "\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import joblib\r\n",
    "import h5py\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from tensorflow.keras.layers import Input, Dropout\r\n",
    "from keras.layers.core import Dense \r\n",
    "from keras.models import Model, Sequential, load_model\r\n",
    "from keras import regularizers\r\n",
    "from keras.models import model_from_json\r\n",
    "\r\n",
    "def init():\r\n",
    "    global model\r\n",
    "    global scaler\r\n",
    "    global init_error\r\n",
    "    \r\n",
    "    try:\r\n",
    "\r\n",
    "        init_error = None\r\n",
    "\r\n",
    "        scaler_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model_files', 'scaler.pkl')\r\n",
    "        model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model_files', 'anomaly_detection_encoder_model.h5')\r\n",
    "        \r\n",
    "        print('Loading scaler from:', scaler_path)\r\n",
    "        scaler = joblib.load(scaler_path)\r\n",
    "        print(scaler)\r\n",
    "\r\n",
    "        print('Loading model from:', model_path)\r\n",
    "        model = load_model(model_path)\r\n",
    "        print(model)\r\n",
    "\r\n",
    "    except Exception as e:\r\n",
    "        init_error = e\r\n",
    "        print(e)\r\n",
    "        \r\n",
    "# note you can pass in multiple rows for scoring\r\n",
    "def run(raw_data):\r\n",
    "\r\n",
    "    if init_error is not None:\r\n",
    "        return 'Init error: {}'.format(str(init_error))\r\n",
    "\r\n",
    "    try:\r\n",
    "        print(\"Received input:\", raw_data)\r\n",
    "    \r\n",
    "        input_df = pd.read_json(raw_data, orient='values')\r\n",
    "        print(input_df)\r\n",
    "    \r\n",
    "        sensor_readings = np.array(input_df)\r\n",
    "        scaled_sensor_readings = scaler.transform(sensor_readings.reshape(1,-1))\r\n",
    "\r\n",
    "        pred_sensor_readings = model.predict(scaled_sensor_readings)\r\n",
    "        score = np.mean(np.abs(scaled_sensor_readings - pred_sensor_readings[0]))\r\n",
    "\r\n",
    "        if score > 0.01:\r\n",
    "            print('WARNING! Abnormal conditions detected')\r\n",
    "            return 1\r\n",
    "        else:\r\n",
    "            print('Everything is ok')\r\n",
    "            return 0\r\n",
    "\r\n",
    "    except Exception as e:\r\n",
    "        error = str(e)\r\n",
    "        return error\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    # Test scoring\r\n",
    "    init()\r\n",
    "    test_row = '[[14.23, 41, 14.4, 318.50, 601.95]]'\r\n",
    "    prediction = run(test_row, {})\r\n",
    "    print(\"Test result: \", prediction)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test deployment of the model as a `LocalWebservice`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core.environment import Environment\r\n",
    "from azureml.core.model import InferenceConfig, Model\r\n",
    "from azureml.core.webservice import LocalWebservice\r\n",
    "\r\n",
    "\r\n",
    "# Create inference configuration based on the environment definition and the entry script\r\n",
    "myenv = Environment.get(ws, 'tf_keras_autoencoder_env')\r\n",
    "inference_config = InferenceConfig(entry_script=\"scoring_scripts/score.py\", environment=myenv)\r\n",
    "# Create a local deployment, using port 8890 for the web service endpoint\r\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\r\n",
    "model = Model(ws, name='Autoencoder_PredMaintenance')\r\n",
    "# Deploy the service\r\n",
    "service = Model.deploy(\r\n",
    "    ws, \"autoencoderpredmaintenance\", [model], inference_config, deployment_config)\r\n",
    "# Wait for the deployment to complete\r\n",
    "service.wait_for_deployment(True)\r\n",
    "# Display the port that the web service is available on\r\n",
    "print(service.port)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Submit predictions to the `LocalWebservice` to confirm the deployed model operates as expected. Note you can modify the scoring script and restart the service using `service.reload()`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "\r\n",
    "#Test normal operation conditions\r\n",
    "test_row = json.dumps([[70, 200, 60.6, 0, 1448.17]])\r\n",
    "test_sample = bytes(test_row, encoding='utf8')\r\n",
    "prediction=service.run(input_data=test_sample)\r\n",
    "print('Expected Result: 0')\r\n",
    "print('Predicted Result: {}'.format(str(prediction)))\r\n",
    "\r\n",
    "\r\n",
    "#Test failure conditions\r\n",
    "test_row = json.dumps([[14.23, 41, 14.4, 318.50, 601.95]])\r\n",
    "test_sample = bytes(test_row, encoding='utf8')\r\n",
    "prediction=service.run(input_data=test_sample)\r\n",
    "print('Expected Result: 1')\r\n",
    "print('Predicted Result: {}'.format(str(prediction)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once your deployment functions as expected, delete the service."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "service.delete()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}